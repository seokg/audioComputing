<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title> Audio Visualization </title>
</head>
<body>
	<h1> Mini Project #1: Pitch Tracking </h1>		
	<p><canvas id='spec_view' style="background: white;"></canvas></p>

	<script>	
	var context;
	var myAudioBuffer = null;
	var analyser;
	
	var spec_view;
	var WIDTH = 640;
	var HEIGHT = 320;
	
	var PITCH_MIN = 36;
	var PITCH_MAX = 96;
	var PITCH_STEP = 0.25;
	var pitch_range = [];
	var pitch_range_hz = [];
	var NUM_HARMONICS = 15;
	

	//
	window.onload=function(){		
		// canvas 
		spec_view = document.getElementById("spec_view");
		spec_view.width =  WIDTH;
		spec_view.height = HEIGHT;	
		
		// create audio context
		context = new AudioContext();
		
		// analyzer
	    analyser = context.createAnalyser();
	    analyser.fftSize = 2048;
		analyser.smoothingTimeConstant = 0;		
		
		// pitch range of interest
		for (var pitch = PITCH_MIN; pitch <= PITCH_MAX; pitch = pitch + PITCH_STEP) 
		{
			pitch_range.push(pitch);
			pitch_range_hz.push(midi2hertz(pitch))
		}		
	}
	
	function midi2hertz(midi) {
		return Math.pow(2,(midi-69.0)/12.0)*440.0;
	}
	
	function draw_spec() {
		// 2d canvas context
		var drawContext = spec_view.getContext('2d');
		
		// fill rectangular
		drawContext.fillStyle = 'rgb(200, 100, 100)';
		drawContext.fillRect(0, 0, WIDTH, HEIGHT);

		// drawing line setting
		drawContext.lineWidth = 2;
		drawContext.strokeStyle = 'rgb(0, 0, 0)';
		drawContext.beginPath();
				
		// get samples 
		var dataArray = new Float32Array(analyser.frequencyBinCount);
		analyser.getFloatFrequencyData(dataArray);
		
		var freq_scale = 10;
		var sliceWidth = WIDTH * 1.0 / (dataArray.length/freq_scale);
		var x = 0;

		// display spectrum up to Nyquist_Frequency/10
		for (var i = 0; i < dataArray.length/freq_scale; i++) {
	        var v = (dataArray[i] + 100)/50;
	        var y = HEIGHT - v * HEIGHT/2;

	    	if(i === 0) {
	        	drawContext.moveTo(x, y);
	        } else {
	        	drawContext.lineTo(x, y);
	        }

	        x += sliceWidth;
		}

		// last touch
		drawContext.lineTo(draw_spec.width, draw_spec.height/2);
		drawContext.stroke();

		//
		// pitch detection
		//
		var pitch_likelihood = new Float32Array(pitch_range_hz.length);
		var power_likelihood = new Float32Array(pitch_range_hz.length);
		
		var power = 0;
		
		for (var i = 0; i < dataArray.length; i++) {
			var power_amp = Math.pow(10,dataArray[i]/10.0);
			binfrqs = i/analyser.fftSize*context.sampleRate;
			
			for (var j = 0 ; j <  pitch_range_hz.length; j++) {
				if ( (binfrqs > pitch_range_hz[j]*0.5) & ( binfrqs <  NUM_HARMONICS* pitch_range_hz[j])) {
					pitch_weight = 0.5 * (1+ Math.cos(2*Math.PI*binfrqs/pitch_range_hz[j]));				
					pitch_likelihood[j] = pitch_likelihood[j] + power_amp*pitch_weight;
					power_likelihood[j] = power_likelihood[j]+ power_amp;
				}
			}
			power = power + power_amp;  
		}
		
		// find max 
		var max_value = -100.0;
		var max_index = 0;
		var harmonicity = 0;
		for (var j = 0 ; j <  pitch_range_hz.length; j++) {
			if (max_value < pitch_likelihood[j] ) {
				max_value = pitch_likelihood[j];
				max_index = j; 
			}
		}
		harmonicity = max_value/power_likelihood[max_index];
		

		drawContext.font = "30px Arial";
		if ((harmonicity > 0.8) & (power > 0.00001) )
		{
			drawContext.strokeText(Math.round(pitch_range_hz[max_index]) + " Hz",100,50);
			drawContext.strokeText(pitch_range[max_index]+ " ST",100,100);
			
			drawContext.fillStyle = 'rgb(100,0,0)';
			drawContext.fillRect(pitch_range_hz[max_index]/context.sampleRate*WIDTH*2*freq_scale-1, 0, 2, HEIGHT);
		}

		// queue for next callback
		window.requestAnimationFrame(draw_spec);
	}
	

	
	if (!navigator.getUserMedia)
		navigator.getUserMedia = (navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
							  
	if (!navigator.getUserMedia)
		alert("Error: getUserMedia not supported!");
						
	// get audio input streaming 				 
	navigator.getUserMedia({audio: true}, onStream, onStreamError)

	// successCallback
	function onStream(stream) {
	    var input = context.createMediaStreamSource(stream);
		
		// Connect graph
		input.connect(analyser);
							  
		// pass through
//		input.connect(context.destination);

		// visualize audio
		draw_spec();	
	}
	
	// errorCallback			 
	function onStreamError(error) {
		console.error('Error getting microphone', error);
	}

	</script>
</body>
</html>